{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/06_CIFAR-10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Use PrettyTensor to simplify Neural Network construction.\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cifar10 import img_size, num_channels, num_classes\n",
    "img_size_cropped = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_image(image, training):\n",
    "    # This function takes a single image as input,\n",
    "    # and a boolean whether to build the training or testing graph.\n",
    "    \n",
    "    if training:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow 0.10.0rc0 whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "    else:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,\n",
    "                                                       target_height=img_size_cropped,\n",
    "                                                       target_width=img_size_cropped)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(images, training):\n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1c3827101d56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistorted_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "distorted_images = pre_process(images=x, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'map/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, 28, 28, 3) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distorted_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(images_train)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = images_train[idx, :, :, :]\n",
    "    y_batch = labels_train[idx, :]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3072)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes from TA's tensorflow tutorial..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We start with our existing model code\n",
    "\n",
    "def compute_logits(x):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "    W = tf.get_variable('W', shape=[32*32*3, 10])\n",
    "    b = tf.get_variable('b', shape=[10])\n",
    "    \n",
    "    logits = tf.add(tf.matmul(x, W), b, name='logits')\n",
    "    return logits\n",
    "\n",
    "# Note: this function is implemented in tensorflow as\n",
    "# tf.nn.softmax_cross_entropy_with_logits\n",
    "\n",
    "# We have included it here for illustration only, please don't use it.\n",
    "def compute_cross_entropy(logits, y):\n",
    "    y_pred = tf.nn.softmax(logits, name='y_pred') # the predicted probability for each example.\n",
    "    # Compute the average cross-entropy across all the examples.\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), axis=[1]))\n",
    "    return cross_entropy\n",
    "\n",
    "def compute_accuracy(logits, y):\n",
    "    prediction = tf.argmax(logits, 1, name='pred_class')\n",
    "    true_label = tf.argmax(y, 1, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, true_label), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: accuracy is 0.09080000221729279\n",
      "Step 11: accuracy is 0.10100000351667404\n",
      "Step 21: accuracy is 0.10199999809265137\n",
      "Step 31: accuracy is 0.10040000081062317\n",
      "Step 41: accuracy is 0.09960000216960907\n",
      "Step 51: accuracy is 0.09759999811649323\n",
      "Step 61: accuracy is 0.10000000149011612\n",
      "Step 71: accuracy is 0.10939999669790268\n",
      "Step 81: accuracy is 0.09600000083446503\n",
      "Step 91: accuracy is 0.09839999675750732\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    logits = compute_logits(x)\n",
    "    loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    opt = tf.train.GradientDescentOptimizer(0.5)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    \n",
    "    # Let's put the summaries below\n",
    "    \n",
    "    # create summary for loss and accuracy\n",
    "    tf.summary.scalar('loss', loss) \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    # create summary for logits\n",
    "    #tf.summary.histogram('logits', logits)\n",
    "    \n",
    "    # create summary for input image\n",
    "    tf.summary.image('input', tf.reshape(x, [-1, 32, 32, 3]))\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter('logs/example1', sess.graph)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for i in range(100):\n",
    "            x_batch, y_true_batch = random_batch()\n",
    "            x_batch=x_batch.reshape(5000,32*32*3)\n",
    "            y_true_batch=y_true_batch.reshape(5000,10)\n",
    "            feed_dict_train = {x: x_batch,y: y_true_batch}\n",
    "            \n",
    "            _, ac, summary = sess.run((train_step, accuracy, summary_op),\n",
    "                                      feed_dict=feed_dict_train)\n",
    "            # write the summary output to file\n",
    "            \n",
    "            summary_writer.add_summary(summary, i)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print('Step {0}: accuracy is {1}'.format(i + 1, ac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Use the Teacher's code (lec04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=images_train[:5000,:,:,:]\n",
    "y_onehot_val=labels_train[:5000,:]\n",
    "X_train=images_train[5000:,:,:,:]\n",
    "y_onehot=labels_train[5000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate performance on some data \n",
    "def perf_eval(logit_pred, y_true):\n",
    "    \"\"\"a function to evaluate performance of predicted y values vs true class labels\"\"\"\n",
    "    # now look at some data\n",
    "    print('    sample pred: {0}\\n    sample true: {1}'.format(np.argmax(logit_pred[0:20],1),np.argmax(y_true[0:20],1)))\n",
    "    # avg accuracy\n",
    "    is_correct_vals = np.equal(np.argmax(logit_pred,1),np.argmax(y_true,1))\n",
    "    #accuracy_vals = np.mean(is_correct_vals)\n",
    "    #print('    mean classification accuracy: {0}%'.format(100*accuracy_vals))\n",
    "    # Dig in a little deeper.  Where did we make correct predictions?  Does this seem reasonable?\n",
    "    print('    correct predictions by class: {0}'.format(y_true[is_correct_vals,:].sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnn conv stuff\n",
    "def conv(x, W):\n",
    "    \"\"\"simple wrapper for tf.nn.conv2d\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def maxpool(x):\n",
    "    \"\"\"simple wrapper for tf.nn.max_pool with stride size 2\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def norm(x): \n",
    "    \"\"\"simple wrapper for tf.nn.lrn... See section 3.3 of Krizhevsky 2012 for details\"\"\"\n",
    "    return tf.nn.lrn(x, depth_radius=5, bias=2, alpha=1e-4, beta=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# elaborate the compute_logits code to include a variety of models\n",
    "def compute_logits(x, model_type, pkeep):\n",
    "    \"\"\"Compute the logits of the model\"\"\"\n",
    "    if model_type=='lr':\n",
    "        W = tf.get_variable('W', shape=[32*32*3, 10])\n",
    "        b = tf.get_variable('b', shape=[10])\n",
    "        logits = tf.add(tf.matmul(x, W), b, name='logits_lr')\n",
    "    elif model_type=='cnn_cf':\n",
    "        # try a 1 layer cnn\n",
    "        n1 = 64\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # fc layer to logits\n",
    "        h_conv1_flat = tf.reshape(h_conv1, [-1, 32*32*n1])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[32*32*n1, 10])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_conv1_flat, W_fc1), b_fc1, name='logits_cnn_cf')\n",
    "    elif model_type=='cnn_cnf':\n",
    "        # try a 1 layer cnn with a normalization layer\n",
    "        n1 = 64\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # norm layer 1\n",
    "        h_norm1 = norm(h_conv1)\n",
    "        # fc layer to logits\n",
    "        h_flat = tf.reshape(h_norm1, [-1, 32*32*n1])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[32*32*n1, 10])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_flat, W_fc1), b_fc1, name='logits_cnn_cnf')     \n",
    "    elif model_type=='cnn_cpncpnff':\n",
    "        # 2 layer cnn\n",
    "        n1 = 32\n",
    "        n2 = 64\n",
    "        n3 = 1024\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # pool 1\n",
    "        h_pool1 = maxpool(h_conv1)\n",
    "        # norm 1\n",
    "        h_norm1 = norm(h_pool1)\n",
    "        # cnn layer 2\n",
    "        W_conv2 = tf.get_variable('W_conv2', shape=[5, 5, n1, n2])\n",
    "        b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "        h_conv2 = tf.nn.relu(tf.add(conv(h_norm1, W_conv2), b_conv2))\n",
    "        # pool 2\n",
    "        h_pool2 = maxpool(h_conv2)\n",
    "        # norm 2\n",
    "        h_norm2 = norm(h_pool2)\n",
    "        # fc layer to logits (8x8 since 2 rounds of maxpool)\n",
    "        h_norm2_flat = tf.reshape(h_norm2, [-1, 8*8*n2])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[8*8*n2, n3])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[n3])\n",
    "        h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_norm2_flat, W_fc1), b_fc1))\n",
    "        # one more fc layer\n",
    "        # ... again, this is the logistic layer with softmax readout\n",
    "        W_fc2 = tf.get_variable('W_fc2', shape=[n3,10])\n",
    "        b_fc2 = tf.get_variable('b_fc2', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_fc1, W_fc2), b_fc2, name='logits_cnn_cpncpnff')\n",
    "    elif model_type=='cnn_cpncpnfdf':\n",
    "        # same as above but add dropout.\n",
    "        # 2 layer cnn\n",
    "        n1 = 32\n",
    "        n2 = 64\n",
    "        n3 = 1024\n",
    "        x_image = tf.reshape(x, [-1,32,32,3]) # batch, then width, height, channels\n",
    "        # cnn layer 1\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 3, n1])\n",
    "        b_conv1 = tf.get_variable('b_conv1', shape=[n1])\n",
    "        h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "        # pool 1\n",
    "        h_pool1 = maxpool(h_conv1)\n",
    "        # norm 1\n",
    "        h_norm1 = norm(h_pool1)\n",
    "        # cnn layer 2\n",
    "        W_conv2 = tf.get_variable('W_conv2', shape=[5, 5, n1, n2])\n",
    "        b_conv2 = tf.get_variable('b_conv2', shape=[n2])\n",
    "        h_conv2 = tf.nn.relu(tf.add(conv(h_norm1, W_conv2), b_conv2))\n",
    "        # pool 2\n",
    "        h_pool2 = maxpool(h_conv2)\n",
    "        # norm 2\n",
    "        h_norm2 = norm(h_pool2)\n",
    "        # fc layer to logits (8x8 since 2 rounds of maxpool)\n",
    "        h_norm2_flat = tf.reshape(h_norm2, [-1, 8*8*n2])\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape=[8*8*n2, n3])\n",
    "        b_fc1 = tf.get_variable('b_fc1', shape=[n3])\n",
    "        h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_norm2_flat, W_fc1), b_fc1))\n",
    "        # insert a dropout layer here.\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, pkeep)\n",
    "        # one more fc layer\n",
    "        # ... again, this is the logistic layer with softmax readout\n",
    "        W_fc2 = tf.get_variable('W_fc2', shape=[n3,10])\n",
    "        b_fc2 = tf.get_variable('b_fc2', shape=[10])\n",
    "        logits = tf.add(tf.matmul(h_fc1_drop, W_fc2), b_fc2, name='logits_cnn_cpncpnfdf')\n",
    "    else: \n",
    "        print('error not a valid model type')\n",
    "\n",
    "    return logits\n",
    "\n",
    "def compute_cross_entropy(logits, y):\n",
    "    # Compute the average cross-entropy across all the examples.\n",
    "    numerical_instability_example = 0\n",
    "    if numerical_instability_example:\n",
    "        y_pred = tf.nn.softmax(logits, name='y_pred') # the predicted probability for each example.\n",
    "        cross_ent = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), reduction_indices=[1]))\n",
    "    else:\n",
    "        sm_ce = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits, name='cross_ent_terms')\n",
    "        cross_ent = tf.reduce_mean(sm_ce, name='cross_ent')\n",
    "    return cross_ent\n",
    "\n",
    "def compute_accuracy(logits, y):\n",
    "    prediction = tf.argmax(logits, 1, name='pred_class')\n",
    "    true_label = tf.argmax(y, 1, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, true_label), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose case to run \n",
    "opt_method = 'sgd'\n",
    "model_type = 'lr' \n",
    "dir_name = 'logs/scratch04x/'\n",
    "batch_size = 1000\n",
    "n=50000\n",
    "n_val=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = np.floor(np.random.rand(batch_size)*(n-n_val)).astype(int)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = X_train[batch,:,:,:].transpose([3,0,1,2]).reshape([batch_size,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3072)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 32, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: training accuracy 0.0910\n",
      "    sample pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.  91.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Step   0: val accuracy 0.0920\n",
      "Step 100: training accuracy 0.1000\n",
      "    sample pred: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.    0.    0.    0.    0.    0.    0.  100.    0.]\n",
      "Step 100: val accuracy 0.1040\n",
      "Step 200: training accuracy 0.1040\n",
      "    sample pred: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 1 8 8 8 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   7.   0.   0.   0.   0.   0.   0.  97.   0.]\n",
      "Step 200: val accuracy 0.1044\n",
      "Step 300: training accuracy 0.1110\n",
      "    sample pred: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.    0.    0.    0.    0.    0.  111.    0.    0.]\n",
      "Step 300: val accuracy 0.0972\n",
      "Step 400: training accuracy 0.0930\n",
      "    sample pred: [5 4 4 4 5 4 5 4 4 4 4 5 4 4 4 5 5 5 4 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.   0.   0.  56.  37.   0.   0.   0.   0.]\n",
      "Step 400: val accuracy 0.1062\n",
      "Step 500: training accuracy 0.0940\n",
      "    sample pred: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.   0.  94.   0.   0.   0.   0.   0.   0.]\n",
      "Step 500: val accuracy 0.0972\n",
      "Step 600: training accuracy 0.0970\n",
      "    sample pred: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.   0.   0.   0.   0.  97.   0.   0.   0.]\n",
      "Step 600: val accuracy 0.1038\n",
      "Step 700: training accuracy 0.1000\n",
      "    sample pred: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.    0.    0.    0.    0.    0.    0.  100.    0.]\n",
      "Step 700: val accuracy 0.1040\n",
      "Step 800: training accuracy 0.1000\n",
      "    sample pred: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.    0.    0.    0.    0.    0.    0.  100.    0.]\n",
      "Step 800: val accuracy 0.1040\n",
      "Step 900: training accuracy 0.1000\n",
      "    sample pred: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.    0.    0.    0.    0.    0.    0.  100.    0.]\n",
      "Step 900: val accuracy 0.1040\n",
      "Step 1000: training accuracy 0.1050\n",
      "    sample pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 105.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "Step 1000: val accuracy 0.1010\n",
      "Step 1100: training accuracy 0.1060\n",
      "    sample pred: [0 6 6 0 0 6 0 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 20.   0.   0.   0.   0.   0.  86.   0.   0.   0.]\n",
      "Step 1100: val accuracy 0.1054\n",
      "Step 1200: training accuracy 0.0940\n",
      "    sample pred: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.   0.  94.   0.   0.   0.   0.   0.   0.]\n",
      "Step 1200: val accuracy 0.0972\n",
      "Step 1300: training accuracy 0.0940\n",
      "    sample pred: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.   0.  94.   0.   0.   0.   0.   0.   0.]\n",
      "Step 1300: val accuracy 0.0972\n",
      "Step 1400: training accuracy 0.0950\n",
      "    sample pred: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.   0.   0.   0.  95.   0.   0.   0.   0.]\n",
      "Step 1400: val accuracy 0.0976\n",
      "Step 1500: training accuracy 0.0890\n",
      "    sample pred: [5 5 5 0 5 0 5 0 5 5 5 5 5 5 5 5 5 5 0 5]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 15.   0.   0.   0.   0.  74.   0.   0.   0.   0.]\n",
      "Step 1500: val accuracy 0.0994\n",
      "Step 1600: training accuracy 0.1000\n",
      "    sample pred: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.  100.    0.    0.    0.    0.    0.    0.    0.]\n",
      "Step 1600: val accuracy 0.1038\n",
      "Step 1700: training accuracy 0.1000\n",
      "    sample pred: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.    0.    0.    0.    0.    0.    0.  100.    0.]\n",
      "Step 1700: val accuracy 0.1040\n",
      "Step 1800: training accuracy 0.1050\n",
      "    sample pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [ 105.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      "Step 1800: val accuracy 0.1010\n",
      "Step 1900: training accuracy 0.0910\n",
      "    sample pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.  91.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Step 1900: val accuracy 0.0920\n",
      "Step 2000: training accuracy 0.1150\n",
      "    sample pred: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [   0.    0.    0.    0.    0.    0.    0.    0.    0.  115.]\n",
      "Step 2000: val accuracy 0.0996\n",
      "Step 2100: training accuracy 0.0970\n",
      "    sample pred: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "    sample true: [6 7 9 0 5 2 3 3 3 9 0 9 2 9 1 0 2 3 9 6]\n",
      "    correct predictions by class: [  0.   0.   0.   0.   0.   0.  97.   0.   0.   0.]\n",
      "Step 2100: val accuracy 0.1038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-cfd07827372c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;31m# now run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             _ , summary = sess.run((train_step, summary_op),\n\u001b[1;32m---> 48\u001b[1;33m                                       feed_dict={x: X_batch, y: y_batch, pkeep:0.85})\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m# write the summary output to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32*3], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    pkeep = tf.placeholder(tf.float32, name='pkeep')\n",
    "    \n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits(x, model_type, pkeep)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    with tf.name_scope('opt'):\n",
    "        if opt_method == 'sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(0.5)\n",
    "        elif opt_method == 'rms':\n",
    "            opt = tf.train.RMSPropOptimizer(.001)\n",
    "        elif opt_method == 'adam':\n",
    "            opt = tf.train.AdamOptimizer(1e-4)\n",
    "        train_step = opt.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        # create summary for loss and accuracy\n",
    "        tf.summary.scalar('loss', loss) \n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        # create summary for logits\n",
    "        tf.summary.histogram('logits', logits)\n",
    "        # create summary for input image\n",
    "        tf.summary.image('input', tf.reshape(x, [-1, 32, 32, 3]))\n",
    "    \n",
    "        summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "        summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "        summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for i in range(20001):\n",
    "            batch = np.floor(np.random.rand(batch_size)*(n-n_val)).astype(int)\n",
    "            X_batch = X_train[batch,:,:,:].transpose([3,0,1,2]).reshape([batch_size,-1])\n",
    "            y_batch = y_onehot[batch]\n",
    "\n",
    "            # now run\n",
    "            _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y: y_batch, pkeep:0.85})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            if i%100==0:\n",
    "                summary_writer_train.add_summary(summary, i)\n",
    "\n",
    "            # print diagnostics\n",
    "            if i%100 == 0:\n",
    "                X_batch = X_train[0:1000,:,:,:].transpose([3,0,1,2]).reshape([1000,-1])\n",
    "                y_batch = y_onehot[0:1000]\n",
    "                (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y: y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "                # further diagnostics\n",
    "                perf_eval(train_logits, y_batch)\n",
    "                \n",
    "            if i%100 == 0:\n",
    "                X_batch = X_val.transpose([3,0,1,2]).reshape([n_val,-1])\n",
    "                y_batch = y_onehot_val\n",
    "                (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch, y:y_batch, pkeep:1.0})\n",
    "                print(\"\\rStep {0:3d}: val accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                summary_writer_val.add_summary(summary, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
